{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6e81ab50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import keras.ops as ops\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2e457530",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data_wrt_stress.csv')\n",
    "\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e4d6e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['smoke_status_num']= df['smoke_status'].apply(lambda x: 0 if x=='never' else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "22b0ccf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "smoke_status_num\n",
       "0    1658\n",
       "1    1160\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['smoke_status_num'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "230dec65",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[[\"dpq_total\", \"hscrp_mg_l_raw\", \"smoke_status_num\",\n",
    "        \"pir\", \"bmx_bmi\"]].values\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a02811d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting VAE training...\n",
      "Epoch 1/50\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - kl_loss: 0.0839 - loss: 3.3907 - reconstruction_loss: 3.3068\n",
      "Epoch 2/50\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - kl_loss: 0.5249 - loss: 4.3889 - reconstruction_loss: 3.8640\n",
      "Epoch 3/50\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - kl_loss: 1.1213 - loss: 5.3731 - reconstruction_loss: 4.2519\n",
      "Epoch 4/50\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - kl_loss: 1.3361 - loss: 5.5080 - reconstruction_loss: 4.1719\n",
      "Epoch 5/50\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - kl_loss: 0.6209 - loss: 2.8371 - reconstruction_loss: 2.2161\n",
      "Epoch 6/50\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - kl_loss: 0.8466 - loss: 4.1976 - reconstruction_loss: 3.3510\n",
      "Epoch 7/50\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - kl_loss: 0.7028 - loss: 1.9501 - reconstruction_loss: 1.2474\n",
      "Epoch 8/50\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - kl_loss: 1.5439 - loss: 7.7279 - reconstruction_loss: 6.1840\n",
      "Epoch 9/50\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - kl_loss: 0.3493 - loss: 6.0508 - reconstruction_loss: 5.7015\n",
      "Epoch 10/50\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - kl_loss: 1.0129 - loss: 7.9789 - reconstruction_loss: 6.9660\n",
      "Epoch 11/50\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - kl_loss: 1.2044 - loss: 5.5555 - reconstruction_loss: 4.3511\n",
      "Epoch 12/50\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - kl_loss: 1.4937 - loss: 2.8780 - reconstruction_loss: 1.3843\n",
      "Epoch 13/50\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - kl_loss: 2.2976 - loss: 5.2977 - reconstruction_loss: 3.0001\n",
      "Epoch 14/50\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - kl_loss: 1.5638 - loss: 4.8249 - reconstruction_loss: 3.2611\n",
      "Epoch 15/50\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - kl_loss: 0.9706 - loss: 2.9421 - reconstruction_loss: 1.9714\n",
      "Epoch 16/50\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - kl_loss: 2.6855 - loss: 3.6767 - reconstruction_loss: 0.9911\n",
      "Epoch 17/50\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - kl_loss: 1.5771 - loss: 6.7587 - reconstruction_loss: 5.1816\n",
      "Epoch 18/50\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - kl_loss: 1.1931 - loss: 3.7640 - reconstruction_loss: 2.5709\n",
      "Epoch 19/50\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - kl_loss: 1.0256 - loss: 2.0043 - reconstruction_loss: 0.9787\n",
      "Epoch 20/50\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - kl_loss: 0.6699 - loss: 3.5938 - reconstruction_loss: 2.9239\n",
      "Epoch 21/50\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - kl_loss: 0.8566 - loss: 4.0522 - reconstruction_loss: 3.1955\n",
      "Epoch 22/50\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - kl_loss: 1.1985 - loss: 4.5839 - reconstruction_loss: 3.3854\n",
      "Epoch 23/50\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - kl_loss: 0.6432 - loss: 2.2453 - reconstruction_loss: 1.6022\n",
      "Epoch 24/50\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - kl_loss: 0.9746 - loss: 4.6866 - reconstruction_loss: 3.7120\n",
      "Epoch 25/50\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - kl_loss: 0.9591 - loss: 3.7582 - reconstruction_loss: 2.7991\n",
      "Epoch 26/50\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - kl_loss: 1.3244 - loss: 4.1096 - reconstruction_loss: 2.7852\n",
      "Epoch 27/50\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - kl_loss: 0.7660 - loss: 1.9993 - reconstruction_loss: 1.2333\n",
      "Epoch 28/50\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - kl_loss: 1.1259 - loss: 4.6965 - reconstruction_loss: 3.5706\n",
      "Epoch 29/50\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - kl_loss: 1.0080 - loss: 4.8374 - reconstruction_loss: 3.8294\n",
      "Epoch 30/50\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - kl_loss: 1.0772 - loss: 2.6847 - reconstruction_loss: 1.6075\n",
      "Epoch 31/50\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - kl_loss: 3.6241 - loss: 6.3180 - reconstruction_loss: 2.6939\n",
      "Epoch 32/50\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - kl_loss: 0.9206 - loss: 4.4338 - reconstruction_loss: 3.5132\n",
      "Epoch 33/50\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - kl_loss: 0.5652 - loss: 3.4736 - reconstruction_loss: 2.9084\n",
      "Epoch 34/50\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - kl_loss: 1.3498 - loss: 4.5535 - reconstruction_loss: 3.2037\n",
      "Epoch 35/50\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - kl_loss: 1.9981 - loss: 3.9851 - reconstruction_loss: 1.9870\n",
      "Epoch 36/50\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - kl_loss: 3.3660 - loss: 6.4546 - reconstruction_loss: 3.0885\n",
      "Epoch 37/50\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - kl_loss: 2.0404 - loss: 10.5582 - reconstruction_loss: 8.5179\n",
      "Epoch 38/50\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - kl_loss: 0.8162 - loss: 4.7330 - reconstruction_loss: 3.9168\n",
      "Epoch 39/50\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - kl_loss: 0.5031 - loss: 2.7832 - reconstruction_loss: 2.2801\n",
      "Epoch 40/50\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - kl_loss: 2.0015 - loss: 6.1604 - reconstruction_loss: 4.1588\n",
      "Epoch 41/50\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - kl_loss: 0.7401 - loss: 1.0937 - reconstruction_loss: 0.3537\n",
      "Epoch 42/50\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - kl_loss: 0.8929 - loss: 1.2561 - reconstruction_loss: 0.3631\n",
      "Epoch 43/50\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - kl_loss: 1.0097 - loss: 1.9431 - reconstruction_loss: 0.9334\n",
      "Epoch 44/50\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - kl_loss: 1.3403 - loss: 3.2369 - reconstruction_loss: 1.8966\n",
      "Epoch 45/50\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - kl_loss: 0.8845 - loss: 2.6530 - reconstruction_loss: 1.7685\n",
      "Epoch 46/50\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - kl_loss: 2.6829 - loss: 7.5342 - reconstruction_loss: 4.8513\n",
      "Epoch 47/50\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - kl_loss: 0.9855 - loss: 1.8447 - reconstruction_loss: 0.8592\n",
      "Epoch 48/50\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - kl_loss: 0.9647 - loss: 3.9277 - reconstruction_loss: 2.9630\n",
      "Epoch 49/50\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - kl_loss: 0.7211 - loss: 3.4374 - reconstruction_loss: 2.7163\n",
      "Epoch 50/50\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - kl_loss: 1.5448 - loss: 3.8020 - reconstruction_loss: 2.2573\n",
      "VAE training complete.\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Saved latent scores to vae_latent_scores.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from keras.optimizers import Adam\n",
    "from keras import Model\n",
    "\n",
    "# --- Configuration ---\n",
    "# Assuming X_scaled and df are defined (e.g., from a previous data loading step)\n",
    "latent_dim = 2 \n",
    "input_dim = X_scaled.shape[1]\n",
    "\n",
    "# --- Sampling Layer Function (Remains the same) ---\n",
    "def sampling(args):\n",
    "    z_mean, z_log_var = args\n",
    "    eps = tf.random.normal(shape=tf.shape(z_mean))\n",
    "    return z_mean + ops.exp(0.5 * z_log_var) * eps\n",
    "\n",
    "# --- 1. Define Encoder (Functional Model) ---\n",
    "encoder_inputs = keras.Input(shape=(input_dim,))\n",
    "h_enc = layers.Dense(32, activation=\"relu\")(encoder_inputs)\n",
    "h_enc = layers.Dense(16, activation=\"relu\")(h_enc)\n",
    "z_mean = layers.Dense(latent_dim, name=\"z_mean\")(h_enc)\n",
    "z_log_var = layers.Dense(latent_dim, name=\"z_log_var\")(h_enc)\n",
    "z = layers.Lambda(sampling, output_shape=(latent_dim,), name=\"z_sample\")([z_mean, z_log_var])\n",
    "encoder = Model(encoder_inputs, [z_mean, z_log_var, z], name=\"encoder\")\n",
    "\n",
    "\n",
    "# --- 2. Define Decoder (Functional Model) ---\n",
    "decoder_input = keras.Input(shape=(latent_dim,), name=\"decoder_input\")\n",
    "d_dec = layers.Dense(16, activation=\"relu\")(decoder_input)\n",
    "d_dec = layers.Dense(32, activation=\"relu\")(d_dec)\n",
    "outputs = layers.Dense(input_dim, name=\"decoder_output\")(d_dec)\n",
    "decoder = Model(decoder_input, outputs, name=\"decoder\")\n",
    "\n",
    "\n",
    "# --- 3. Define Custom VAE Model (Subclassing) ---\n",
    "class VAE(Model):\n",
    "    def __init__(self, encoder, decoder, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        # self.mse_loss_fn = keras.losses.MeanSquaredError(reduction='none') # REMOVED\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # Forward pass: Encode, Sample, Decode\n",
    "        z_mean, z_log_var, z = self.encoder(inputs)\n",
    "        reconstruction = self.decoder(z)\n",
    "        return reconstruction\n",
    "\n",
    "    def train_step(self, data):\n",
    "        # Unpack the data (since X_scaled is both input and target)\n",
    "        x = data[0]\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            # Forward pass\n",
    "            z_mean, z_log_var, z = self.encoder(x)\n",
    "            reconstruction = self.decoder(z)\n",
    "\n",
    "            # --- VAE Loss Calculation (FIXED) ---\n",
    "            \n",
    "            # 1. Reconstruction Loss (FIX: Use manual ops calculation)\n",
    "            # This explicitly calculates the squared difference element-wise,\n",
    "            # ensuring the shape is (batch_size, input_dim).\n",
    "            reconstruction_error = ops.square(x - reconstruction)\n",
    "\n",
    "            # Sum across the feature dimension (axis=1), then mean across the batch\n",
    "            reconstruction_loss = ops.mean(ops.sum(reconstruction_error, axis=1))\n",
    "\n",
    "            # 2. KL Divergence Loss\n",
    "            kl_loss = -0.5 * ops.mean(\n",
    "                ops.sum(1 + z_log_var - ops.square(z_mean) - ops.exp(z_log_var), axis=1)\n",
    "            )\n",
    "\n",
    "            # Total VAE Loss\n",
    "            total_loss = reconstruction_loss + kl_loss\n",
    "\n",
    "        # Compute gradients and update weights\n",
    "        trainable_vars = self.trainable_variables\n",
    "        gradients = tape.gradient(total_loss, trainable_vars)\n",
    "        self.optimizer.apply_gradients(zip(gradients, trainable_vars))\n",
    "\n",
    "        # Return a dict mapping metric names to current values\n",
    "        return {\n",
    "            \"loss\": total_loss,\n",
    "            \"reconstruction_loss\": reconstruction_loss,\n",
    "            \"kl_loss\": kl_loss,\n",
    "        }\n",
    "\n",
    "# --- Initialization and Training (Unchanged) ---\n",
    "vae = VAE(encoder, decoder)\n",
    "vae.compile(optimizer=Adam())\n",
    "\n",
    "print(\"Starting VAE training...\")\n",
    "vae.fit(X_scaled, X_scaled, epochs=50, batch_size=32, verbose=1)\n",
    "print(\"VAE training complete.\")\n",
    "\n",
    "# --- Encoding and Saving (using the original encoder for simplicity) ---\n",
    "# NOTE: The custom VAE class uses an internal encoder, which is the same model defined above.\n",
    "# We can use the separate encoder model for prediction.\n",
    "latent = encoder.predict(X_scaled)[0] # Get z_mean for embedding\n",
    "\n",
    "df[\"latent1\"] = latent[:, 0]\n",
    "df[\"latent2\"] = latent[:, 1]\n",
    "\n",
    "df.to_csv(\"vae_latent_scores.csv\", index=False)\n",
    "\n",
    "print(\"Saved latent scores to vae_latent_scores.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac4cfc57",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
